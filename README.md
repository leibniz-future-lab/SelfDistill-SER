# SelfDistill-SER

This is a Python and PyTorch code for the self-distillation framework in our paper: 

>Zhao Ren, Thanh Tam Nguyen, Yi Chang, and Björn W. Schuller. Fast yet effective speech emotion recognition with self-distillation. https://arxiv.org/abs/2210.14636

## Citation

```
@misc{ren2022fast,
      title={Fast yet effective speech emotion recognition with self-distillation}, 
      author={Zhao Ren and Thanh Tam Nguyen and Yi Chang and Björn W. Schuller},
      year={2022},
      eprint={2210.14636},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      note={5 pages}
}
```

## Abstract

In this paper, self-distillation was applied to produce a fast and effective SER model, by simultaneously fine-tuning wav2vec 2.0 and training its shallower versions.

## Config

In the runme.sh, all of the paths can be set and run corresponding python files via 

```
sh runme.sh
```

